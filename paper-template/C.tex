\section{Discussion And Ethical Analysis}
  \\
  
  When analysing ethical aspects in regards of the AI Act, one has to take into consideration that the development of the proposal itself has its origin in the High-Level Expert Group on AI [\citet{HLEG_2019}], which already set up ethics guidelines for trustworthy AI in 2019 [\citet{ai_act}]. Therefore it can be said that the importance of ethical evaluation of AI was thought as an important part of the act from the beginning. \\
  
As AI systems should improve individual and collective wellbeing, the Ethics Guidelines of the HLEG propose four ethical principles [\citet{HLEG_2019}]: respect for human autonomy, fairness, explainability and prevention of harm. In the following section these ethical imperatives will be discussed on the example of KI4LSA of Fraunhofer IOSB-INA. The project itself is only deployed in real world usage applying a second security layer as described in the introduction. For the analysis though it is assumed that the AI is working without these restrictions while taking them in consideration if necessary.

The first ethical principle: respect for human autonomy is requiring the AI system to use a human-centric design and not unjustifiably subordinate, coerce, deceive, manipulate, condition or herd humans (ibid.). In this case of traffic lights, the already used system is human-centric as being focused on organising human travel. The AI is merely improving this system, aiming for a reduction of travel time. KI4LSA showed an improved traffic flow of 10\%
and effects on traffic in the surrounding area [\citet{KI4LSA_presentation}].  It is in its core expanding human autonomy and therefore in line with this ethical principle.

The principle of fairness covers many different interpretations of fairness, be it on the level of the individual, like discrimination, or societal fairness, like equal opportunities. As traffic lights are a public good, everybody has access and the used sensors do only recognize vehicles, without differentiation. A whole different case is the sister project KI4PED, which aims to improve traffic lights for pedestrians and does not analyse cars, but humans - especially with regards to their disabilities, which leads to longer green phases. This is highly personal data and would raise a lot of other questions. But this is not the case for KI4LSA and as a consequence it is a fair AI system.

With being a fair system, comes the requirement of identifiable and explicable decision making. While in other cases explicability of AI is of very high relevance (i.e. judicial decisions), one can argue that this is not the case here. Humans are accustomed to the behaviour of traffic lights and even though on an individual level one could feel unsure about the effectiveness of red and green times, this is highly subjective and already the case without an AI system in place. Again in KI4PED, the differentiation between disabilities and the decision making would have to be much more explicable. As cars are all considered equal (despite given differences in size and acceleration), there is no need for further explanation.

Lastly it can be argued that the prevention of harm is the most important principle in this list. It does not only cover mental and physical integrity, but also human dignity and the natural environment. Handing over traffic regulation to an AI might pose the risk of accidents resulting from miscalculations and high speeds. Humans trust traffic lights to show correct signals and behave accordingly.

First of all one could raise questions on the sensors, which analyse incoming traffic. Bad weather conditions like rain, fog or snow can challenge the system, the experiment showed. Anyhow video and radar sensors deliver an accuracy of 83\% 
(ibid.), much higher than regular sensors and can also provide data at night time. If problems occur, the AI would restart itself and the second security layer would take over. While sensor data is an important start, the real question lies in the decision making of the system. To make the AI as secure as possible, Reinforced Learning was applied. This training process is pushing the AI towards improving the traffic flow and avoiding mistakes. It was counted as a mistake when the AI was making decisions which contradicted the requirements of the second security layer, e.g. red and green signals on opposing sites. As a consequence the AI is trained within the boundaries of the security layer while improving the traffic flow. As said in the beginning, the real world usage is still using a real second security layer in addition to the trained security layer.

An interesting side effect can be seen when taking the harm of the natural environment into the focus. The study (ibid.) showed a reduction of 10-20\%
 of CO2 emissions while applying the system in contrast to standard regulation. One could argue the AI is not even not harming the environment, but improving it instead.
Taking these points into consideration one can argue that the KI4LSA traffic light system is preventing harm as required in the guidelines.\\

Usually tensions occur between the principles described above. In the case of improved traffic lights like KI4LSA though, the values align: more human autonomy is given through improved traffic flow, fairness and explainability are given in anonymised traffic and prevention of harm is assured through various security layers, while less greenhouse gas emissions occur. This can all be explained by the fact that this AI application is merely improving an already existing, understood and accepted concept of human-machine behaviour i.e. traffic regulation, which reduced the number of issues, compared to other AI applications.\\

\\

Analysing the KI4LSA system from an external perspective one can raise multiple further, more fundamental points as ethical questions can go deeper than recommended by the guidelines of the High-Level Expert Group on AI.

First issue that comes to mind is the exclusive focus on automotives. The current approach is solely relying on scanned vehicles like cars, lorries and buses. It is not optimised for motorcycles and bikes, which can be seen as an unfair towards humans preferring to ride those for various (especially economical) reasons. Car drivers might profit from a better traffic flow, but this could also lead to higher speeds, more noise pollution and higher risk for other road users, especially pedestrians. Other traffic participants might not as much profit from the AI application which might disadvantage them compared to car drivers directly and indirectly. Not being able to be part of the car traffic, might motivate people to switch to cars instead, which could zero out the effect because of more cars on the road. 

In an even bigger context, encouraging people to use individual mobility instead of public transport could slow down traffic in the long run. Improving car traffic without similar or greater improvements in public transport could nullify the positive effects in the future.

Connected with all these arguments is the issue of climate change: giving incentives to stick with a certain traffic system that is responsible for 19\%
of Germany's greenhouse gas emissions [\citet{umweltbundesamt}], by improving it might not be the way to fight the climate crisis effectively. Of course the improved traffic flow can locally reduce emissions, as said before, but the overall concept of individual mobility should be considered problematic, looking at the far to low emission reductions in the mobility sector (ibid.). \\

Applying the ethical imperatives from before, fairness towards people without a car is questionable and fairness towards future generations might also be when emissions are not reduced sufficiently. This goes hand in hand with harm to current and future populations and therefore contradicts the points made before on a bigger scale.

On the other hand development in AI usage in traffic could also be a first step towards a new way of traffic with autonomous vehicles and vehicle-to-x communication. One could argue that in the upcoming future cars could be first of all fully electric, which, provided coming from a renewable power source, would not be harmful to climate and the environment. And with a Sharing Economy the number of vehicles on the street (driving and standing) could be reduced massively. This in combination with said traffic light system, could lead to a very efficient traffic flow without the downsides mentioned above.\\

The KI4LSA AI traffic light system meets all ethics requirements of the HLEG guidelines and can therefore be applied in the EU. To what extend one wants to put the consequences of further improved individual mobility into considerations, is something for society to debate and decide on. 


